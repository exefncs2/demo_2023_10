version: '3'
services:
  postgres:
    image: postgres:13
    environment:
        POSTGRES_USER: airflow
        POSTGRES_PASSWORD: airflow
        POSTGRES_DB: airflow
    volumes:
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql # 新增挂载 init.sql 文件
    ports:
      - "5434:5432"
    restart: always
    networks:
      - all_link_network
  airflow:
    image: apache/airflow:slim-2.7.3-python3.9
    ports:
      - "5555:8080"
      - "5432:5432" # 若已占用代表all_link_network 已經建立 刪除執行即可
    volumes:
      
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./.env:/opt/airflow/.env
      - ./airflow.cfg:/opt/airflow/airflow.cfg
      - ./work:/opt/airflow/work

    environment:
      AIRFLOW__CORE__LOAD_EXAMPLES: False
      LANGUAGE: en_US.UTF-8
      LANG:  en_US.UTF-8
      LC_CTYPE: en_US.UTF-8
      LC_MESSAGES: en_US.UTF-8
      SLUGIFY_USES_TEXT_UNIDECODE: yes
      
      # 資料來源bucket
      bucket_name: <buckets_name>
      bucket_path: <buckets_path>

      # update用資料bucket
      update_bucket_name: <buckets_name>
      update_bucket_path: <buckets_update_path>
      
      # 資料來源bigquery
      dataset: <dataset>

      # 資料來源bigquery
      dataset_update: <dataset_update>


      # 位置表名
      schema: <schema>
      origin_table_name: <base_table>
      update_origin_table_name: <update_table>
      dbt_dir: <dbt_dir> 
      update_dbt_dir: <update_dbt_dir>
      
      # 連線資訊 建立時請用下列名稱
      postgres_conn: <docker_postgres_conn_name>
      google_cloud_storage_conn: <gcp_conn_file>

      
    depends_on:
      - postgres
    command:
      -  /opt/airflow/work/start.sh  # 这里运行 Shell 脚本
    entrypoint: 
      -  /opt/airflow/work/init.sh
    
    networks:
      - all_link_network

networks:
  all_link_network:
    external: false
    name: all_link_network